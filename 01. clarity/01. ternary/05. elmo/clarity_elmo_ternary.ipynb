{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Allennlp ELMO BRWAC - Clareza-Balanced-Multiclass-response.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaa8g26efCNu",
        "colab_type": "text"
      },
      "source": [
        "# Reference\n",
        "\n",
        "*   Original Tutorial: http://mlexplained.com/2019/01/30/an-in-depth-tutorial-to-allennlp-from-basics-to-elmo-and-bert/\n",
        "*   Original Colab: https://colab.research.google.com/github/dudeperf3ct/DL_notebooks/blob/master/tl_nlp/tl_nlp_allennlp.ipynb#scrollTo=pDBy4oPBOftc\n",
        "*   Modified ELMO Colab for text classification: https://github.com/keitakurita/Practical_NLP_in_PyTorch/blob/master/allennlp/elmo_text_classification.ipynb\n",
        "\n",
        "#### Other references:\n",
        "\n",
        "*   http://www.realworldnlpbook.com/blog/improving-sentiment-analyzer-using-elmo.html\n",
        "*   https://dudeperf3ct.github.io/nlp/transfer/learning/2019/02/22/Power-of-Transfer-Learning-in-NLP/#elmo\n",
        "*   https://allennlp.org/tutorials\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDBy4oPBOftc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "762b0da8-4f10-443e-90b6-287290535d35"
      },
      "source": [
        "#!pip install -q allennlp==0.8.2\n",
        "\n",
        "import allennlp\n",
        "allennlp.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.8.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSJJlBjOijHx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "303cac13-69be-4936-821a-53c1e5da0d31"
      },
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.0.18'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEEEik2gglSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ea8be57-062d-4c3f-cf7a-0831264a562f"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.6.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbUhD7ZdgpSV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d5dafffa-30a7-4954-c4ae-05df019f4ed3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Aug 31 11:28:40 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n2M5Xe8gsQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.set_device(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrHyuxNgRwXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "53f2cf03-53cd-4108-e8cc-dd71fc87ef23"
      },
      "source": [
        "# https://spacy.io/models/pt\n",
        "\n",
        "! python -m spacy download pt\n",
        "! python -m spacy download pt_core_news_sm\n",
        "\n",
        "cur_language = 'pt_core_news_sm'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pt_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz#egg=pt_core_news_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "\n",
            "    You can now load the model via spacy.load('pt')\n",
            "\n",
            "Requirement already satisfied: pt_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz#egg=pt_core_news_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/pt_core_news_sm\n",
            "\n",
            "    You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrfKWMPPLjfc",
        "colab_type": "text"
      },
      "source": [
        "## e-SIC Dataset\n",
        "\n",
        "Code Adapted from : [Link](https://github.com/keitakurita/Practical_NLP_in_PyTorch)\n",
        "\n",
        "Paper ELMo : [Link](https://arxiv.org/pdf/1802.05365.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmROOTrsNK3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f1bbf33-4d96-4a50-8151-696508d8f48a"
      },
      "source": [
        "from pathlib import Path\n",
        "from typing import *\n",
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "from overrides import overrides\n",
        "\n",
        "from allennlp.data import Instance\n",
        "from allennlp.data.token_indexers import TokenIndexer\n",
        "from allennlp.data.tokenizers import Token\n",
        "from allennlp.nn import util as nn_util\n",
        "from allennlp.common.checks import ConfigurationError\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "print(USE_GPU)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lobzm4ENeRaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Variables\n",
        "params = {\n",
        "    'exp': 'Clareza-Balanced-Multiclass-COH-METRIX',\n",
        "    'data': 'resp-text',\n",
        "    'label': 'Clareza',\n",
        "    'BATCH_SIZE': 64,\n",
        "    'MAX_LEN': 128,\n",
        "    'lr': 3e-4,\n",
        "    'epochs': 10,\n",
        "    'hidden_sz': 64,\n",
        "    'max_vocab_size': 10000\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m3ZGpgfehio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9064182-c286-4a0b-c21a-3898866ba1e7"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Driver\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tocRrPaaUzTr",
        "colab": {}
      },
      "source": [
        "# Load Data\n",
        "binary = False\n",
        "exp = params.get('exp')\n",
        "if 'Binary' in exp:\n",
        "  binary = True\n",
        "\n",
        "base_path = '/content/gdrive/My Drive/Colab Notebooks/Simple/Datasets/' + exp\n",
        "save_path = '/content/gdrive/My Drive/Colab Notebooks/Simple/' + exp + '/output/'\n",
        "\n",
        "data = params.get('data')\n",
        "label = params.get('label')\n",
        "\n",
        "x_train_file = 'X_train.csv'\n",
        "y_train_file = 'y_train.csv'\n",
        "x_test_file = 'X_test.csv'\n",
        "y_test_file = 'y_test.csv'\n",
        "\n",
        "#Load data\n",
        "X_train = pd.read_csv(os.path.join(base_path, x_train_file), sep=';', encoding='utf-8')\n",
        "y_train = pd.read_csv(os.path.join(base_path, y_train_file), sep=';', encoding='utf-8')\n",
        "X_test = pd.read_csv(os.path.join(base_path, x_test_file), sep=';', encoding='utf-8')\n",
        "y_test = pd.read_csv(os.path.join(base_path, y_test_file), sep=';', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7vOfU5_eS5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "1e4c6878-0e08-4cde-b5f0-c5dc3bc75913"
      },
      "source": [
        "#df = pd.concat([X_train, X_test], axis=0)\n",
        "train_df = pd.concat([X_train.loc[:,['pid', data]], pd.DataFrame(y_train[label], columns=[label])], axis=1)\n",
        "test_df = pd.concat([X_test.loc[:,['pid', data]], pd.DataFrame(y_test[label], columns=[label])], axis=1)\n",
        "\n",
        "train_df['positive'] = train_df.apply(lambda row: 1 if row[label] == 2 else 0, axis=1)\n",
        "train_df['negative'] = train_df.apply(lambda row: 1 if row[label] == 0 else 0, axis=1)\n",
        "train_df['neutral'] = train_df.apply(lambda row: 1 if row[label] == 1 else 0, axis=1)\n",
        "\n",
        "test_df['positive'] = test_df.apply(lambda row: 1 if row[label] == 2 else 0, axis=1)\n",
        "test_df['negative'] = test_df.apply(lambda row: 1 if row[label] == 0 else 0, axis=1)\n",
        "test_df['neutral'] = test_df.apply(lambda row: 1 if row[label] == 1 else 0, axis=1)\n",
        "\n",
        "train_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pid</th>\n",
              "      <th>resp-text</th>\n",
              "      <th>Clareza</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>545719</td>\n",
              "      <td>Esclarecemos que a Ebserh disponibiliza inform...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>558682</td>\n",
              "      <td>Prezado a Senhor a , Segue anexa , resposta ao...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>555475</td>\n",
              "      <td>Prezado senhor , não há , no momento , nenhuma...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>550699</td>\n",
              "      <td>Prezado Welington , O Instituto Federal agrade...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>359635</td>\n",
              "      <td>Prezada Sra . Vivian , O DEPARTAMENTO DE ASSI...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>551514</td>\n",
              "      <td>Prezado senhor , sobre o assunto , deve-se obs...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>528654</td>\n",
              "      <td>Prezado senhor Allan de Oliveira Barros , O úl...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>506126</td>\n",
              "      <td>Prezado a Senhor a Deuseni , informamos que nã...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>421000</td>\n",
              "      <td>Prezada Senhora , Em atendimento à solicitação...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>293338</td>\n",
              "      <td>Prezada Sra, Em atenção à solicitação de V.Sª....</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      pid                                          resp-text  ...  negative  neutral\n",
              "0  545719  Esclarecemos que a Ebserh disponibiliza inform...  ...         0        1\n",
              "1  558682  Prezado a Senhor a , Segue anexa , resposta ao...  ...         0        1\n",
              "2  555475  Prezado senhor , não há , no momento , nenhuma...  ...         0        0\n",
              "3  550699  Prezado Welington , O Instituto Federal agrade...  ...         0        1\n",
              "4  359635   Prezada Sra . Vivian , O DEPARTAMENTO DE ASSI...  ...         0        1\n",
              "5  551514  Prezado senhor , sobre o assunto , deve-se obs...  ...         1        0\n",
              "6  528654  Prezado senhor Allan de Oliveira Barros , O úl...  ...         1        0\n",
              "7  506126  Prezado a Senhor a Deuseni , informamos que nã...  ...         1        0\n",
              "8  421000  Prezada Senhora , Em atendimento à solicitação...  ...         0        0\n",
              "9  293338  Prezada Sra, Em atenção à solicitação de V.Sª....  ...         0        0\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu5wUlQ5kTxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "87e63431-eb87-4ed1-ea3c-a69fcecbdae4"
      },
      "source": [
        "test_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pid</th>\n",
              "      <th>resp-text</th>\n",
              "      <th>Clareza</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>312962</td>\n",
              "      <td>Prezado (a) Senhor (a) 1. Em atenção ao pedido...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>438696</td>\n",
              "      <td>O Serviço de Informações ao Cidadão SIC da Agê...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>465158</td>\n",
              "      <td>Prezado a Cidadão ã , 1 . Conforme solicitação...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>568962</td>\n",
              "      <td>Prezado , O Serviço de Informações ao Cidadão...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>466115</td>\n",
              "      <td>Prezado a Senhor a , Em atendimento ao pedido ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>326588</td>\n",
              "      <td>Prezado Senhor, A sua manifestação não encontr...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>440392</td>\n",
              "      <td>Prezado Cidadão , Temos a esclarecer que receb...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>395222</td>\n",
              "      <td>Senhor João , O Serviço de Informações ao Cida...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>506342</td>\n",
              "      <td>Bom dia , Maiara ! A Universidade Federal de V...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>366116</td>\n",
              "      <td>Prezado a Senhor a , Esclarecemos que por meio...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      pid                                          resp-text  ...  negative  neutral\n",
              "0  312962  Prezado (a) Senhor (a) 1. Em atenção ao pedido...  ...         0        0\n",
              "1  438696  O Serviço de Informações ao Cidadão SIC da Agê...  ...         1        0\n",
              "2  465158  Prezado a Cidadão ã , 1 . Conforme solicitação...  ...         0        1\n",
              "3  568962   Prezado , O Serviço de Informações ao Cidadão...  ...         0        1\n",
              "4  466115  Prezado a Senhor a , Em atendimento ao pedido ...  ...         0        1\n",
              "5  326588  Prezado Senhor, A sua manifestação não encontr...  ...         1        0\n",
              "6  440392  Prezado Cidadão , Temos a esclarecer que receb...  ...         1        0\n",
              "7  395222  Senhor João , O Serviço de Informações ao Cida...  ...         0        0\n",
              "8  506342  Bom dia , Maiara ! A Universidade Federal de V...  ...         1        0\n",
              "9  366116  Prezado a Senhor a , Esclarecemos que por meio...  ...         0        0\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ6GJQP2amGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  os.mkdir('data/')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "train_df.to_csv('data/train_df.csv', index=False)\n",
        "test_df.to_csv('data/test_df.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWJVOsTHNO74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "        \n",
        "config = Config(\n",
        "    testing=False,\n",
        "    seed=1,\n",
        "    batch_size=params.get('BATCH_SIZE'),\n",
        "    lr=params.get('lr'),\n",
        "    epochs=params.get('epochs'),\n",
        "    hidden_sz=params.get('hidden_sz'),\n",
        "    max_seq_len=params.get('MAX_LEN'), # required to limit memory usage\n",
        "    max_vocab_size=params.get('max_vocab_size'),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWEsfzKbNPEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(config.seed)\n",
        "DATA_ROOT = Path(\"data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ux5_-oyTld1",
        "colab_type": "text"
      },
      "source": [
        "### Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97kO5UV5NPKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.data.dataset_readers import DatasetReader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEFPAZf7NPM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_cols = [\"negative\", \"neutral\", \"positive\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgTrDjOkPcED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.fields import TextField, MetadataField, ArrayField\n",
        "\n",
        "class SentimentDatasetReader(DatasetReader):\n",
        "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
        "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
        "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
        "        super().__init__(lazy=False)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    @overrides\n",
        "    def text_to_instance(self, tokens: List[Token], id: str=None, labels: np.ndarray=None) -> Instance:\n",
        "        sentence_field = TextField(tokens, self.token_indexers)\n",
        "        fields = {\"tokens\": sentence_field}\n",
        "        \n",
        "        id_field = MetadataField(id)\n",
        "        fields[\"id\"] = id_field\n",
        "        \n",
        "        if labels is None:\n",
        "            labels = np.zeros(len(label_cols))\n",
        "        label_field = ArrayField(array=labels)\n",
        "        fields[\"label\"] = label_field\n",
        "\n",
        "        return Instance(fields)\n",
        "    \n",
        "    @overrides\n",
        "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
        "        df = pd.read_csv(file_path)\n",
        "        if config.testing: df = df.head(1000)\n",
        "        for i, row in df.iterrows():\n",
        "            yield self.text_to_instance([Token(x) for x in self.tokenizer(row[data])], None, row[label_cols].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Po9wuzw-rZ9x"
      },
      "source": [
        "## ELMo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cU-g0PQ-rZ9_",
        "colab": {}
      },
      "source": [
        "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
        "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n",
        "\n",
        "# the token indexer is responsible for mapping tokens to integers\n",
        "token_indexer = ELMoTokenCharactersIndexer()\n",
        "\n",
        "def tokenizer(x: str):\n",
        "    return [w.text for w in SpacyWordSplitter(language=cur_language, pos_tags=False).split_words(x)[:config.max_seq_len]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s8p-gJ-9rZ-P",
        "colab": {}
      },
      "source": [
        "reader = SentimentDatasetReader(\n",
        "    tokenizer=tokenizer,\n",
        "    token_indexers={\"tokens\": token_indexer}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fX3yQmXurZ-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c90ccd9e-0fca-4fcc-82b0-7183ecf0f1ab"
      },
      "source": [
        "train_ds = reader.read(DATA_ROOT / \"train_df.csv\")\n",
        "print(len(train_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4832it [00:15, 312.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hrDWynosqme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c4e69715-6f20-46be-a43a-6a0e32bd0c88"
      },
      "source": [
        "test_ds = reader.read(DATA_ROOT / \"test_df.csv\")\n",
        "print(len(test_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2071it [00:05, 362.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovgOH85rqC0J",
        "colab_type": "text"
      },
      "source": [
        "### Checking Tokens & Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0KqdOBUZrZ-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ee45405-50a8-4cdd-e779-eb50c6e4fa91"
      },
      "source": [
        "vars(train_ds[0].fields[\"tokens\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_indexed_tokens': None,\n",
              " '_indexer_name_to_indexed_token': None,\n",
              " '_token_indexers': {'tokens': <allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer at 0x7f8b88c4fcc0>},\n",
              " 'tokens': [Esclarecemos,\n",
              "  que,\n",
              "  a,\n",
              "  Ebserh,\n",
              "  disponibiliza,\n",
              "  informações,\n",
              "  em,\n",
              "  conformidade,\n",
              "  com,\n",
              "  o,\n",
              "  disposto,\n",
              "  naPortaria,\n",
              "  Conjunta,\n",
              "  número,\n",
              "  5,\n",
              "  da,\n",
              "  Secretaria,\n",
              "  de,\n",
              "  Orçamento,\n",
              "  Federal,\n",
              "  -,\n",
              "  SOF,\n",
              "  e,\n",
              "  da,\n",
              "  Secretaria,\n",
              "  de,\n",
              "  Gestão,\n",
              "  Pública,\n",
              "  -,\n",
              "  SEGEP,\n",
              "  ,,\n",
              "  de,\n",
              "  5,\n",
              "  de,\n",
              "  agosto,\n",
              "  de,\n",
              "  2015,\n",
              "  ,,\n",
              "  por,\n",
              "  meio,\n",
              "  da,\n",
              "  publicação,\n",
              "  ,,\n",
              "  desde,\n",
              "  outubro,\n",
              "  de,\n",
              "  2015,\n",
              "  ,,\n",
              "  no,\n",
              "  endereço,\n",
              "  eletrônico,\n",
              "  http,\n",
              "  :,\n",
              "  www,\n",
              "  .,\n",
              "  ebserh,\n",
              "  .,\n",
              "  governo,\n",
              "  .,\n",
              "  br,\n",
              "  web,\n",
              "  portal,\n",
              "  -,\n",
              "  ebserh,\n",
              "  empregados,\n",
              "  ,,\n",
              "  das,\n",
              "  seguintes,\n",
              "  Tabelas,\n",
              "  :,\n",
              "  I,\n",
              "  -,\n",
              "  Quantitativo,\n",
              "  Físico,\n",
              "  de,\n",
              "  Empregados,\n",
              "  Cargos,\n",
              "  Efetivos,\n",
              "  2,\n",
              "  -,\n",
              "  Remuneração,\n",
              "  de,\n",
              "  Cargos,\n",
              "  Efetivos,\n",
              "  3,\n",
              "  -,\n",
              "  Quantitativo,\n",
              "  Físico,\n",
              "  de,\n",
              "  Cargos,\n",
              "  em,\n",
              "  Comissão,\n",
              "  e,\n",
              "  Funções,\n",
              "  Gratificadas,\n",
              "  4,\n",
              "  -,\n",
              "  Remuneração,\n",
              "  de,\n",
              "  Cargos,\n",
              "  em,\n",
              "  Comissão,\n",
              "  e,\n",
              "  Funções,\n",
              "  Gratificadas,\n",
              "  V,\n",
              "  -,\n",
              "  Quantitativo,\n",
              "  Físico,\n",
              "  de,\n",
              "  Pessoal,\n",
              "  Temporário,\n",
              "  VI,\n",
              "  -,\n",
              "  Quantitativo,\n",
              "  de,\n",
              "  Beneficiários,\n",
              "  e,\n",
              "  Valores,\n",
              "  Per,\n",
              "  Capita,\n",
              "  de,\n",
              "  Benefícios,\n",
              "  Assistenciais,\n",
              "  Os,\n",
              "  modelos,\n",
              "  das,\n",
              "  tabelas]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N6lwAUZjrZ_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb6fad48-97e7-4b7f-8950-82e47ea2c530"
      },
      "source": [
        "vars(train_ds[0].fields[\"label\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'array': array([0, 1, 0], dtype=object), 'padding_value': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t1TFE9kvrZ_O"
      },
      "source": [
        "### Prepare Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TsN2VpKSrZ_T",
        "colab": {}
      },
      "source": [
        "vocab = Vocabulary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZSDayQsgrZ_g"
      },
      "source": [
        "### Prepare Iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vc7kgux6rZ_p",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import BucketIterator\n",
        "\n",
        "iterator = BucketIterator(batch_size=config.batch_size, sorting_keys=[(\"tokens\", \"num_tokens\")],)\n",
        "iterator.index_with(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aXuusjbgraA1"
      },
      "source": [
        "### Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zl1OCBVEraA_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "21b70e8d-4045-475e-becd-d8ef443acafe"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
        "from allennlp.nn.util import get_text_field_mask\n",
        "from allennlp.models import Model\n",
        "from allennlp.modules.text_field_embedders import TextFieldEmbedder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QoexCIfmraBM",
        "colab": {}
      },
      "source": [
        "class BaselineModel(Model):\n",
        "    def __init__(self, word_embeddings: TextFieldEmbedder,\n",
        "                 encoder: Seq2VecEncoder,\n",
        "                 out_sz: int=len(label_cols)):\n",
        "        super().__init__(vocab)\n",
        "        self.word_embeddings = word_embeddings\n",
        "        self.encoder = encoder\n",
        "        self.projection = nn.Linear(self.encoder.get_output_dim(), out_sz)\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "        \n",
        "    def forward(self, tokens: Dict[str, torch.Tensor],\n",
        "                id: Any, label: torch.Tensor) -> torch.Tensor:\n",
        "        mask = get_text_field_mask(tokens)\n",
        "        embeddings = self.word_embeddings(tokens)\n",
        "        state = self.encoder(embeddings, mask)\n",
        "        class_logits = self.projection(state)\n",
        "        \n",
        "        output = {\"class_logits\": class_logits}\n",
        "        output[\"loss\"] = self.loss(class_logits, label)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t-RIhCDvraBb"
      },
      "source": [
        "### Prepare Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ng3lzsNMraBf",
        "colab": {}
      },
      "source": [
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
        "\n",
        "# https://allennlp.org/elmo - PORTUGUESE BRWAC\n",
        "options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/contributed/pt/brwac/options.json'\n",
        "weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/contributed/pt/brwac/elmo_pt_weights_dgx1.hdf5'\n",
        "\n",
        "elmo_embedder = ElmoTokenEmbedder(options_file, weight_file)\n",
        "word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZAbX3qNtraBx",
        "colab": {}
      },
      "source": [
        "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
        "\n",
        "# Create Encoder\n",
        "encoder: Seq2VecEncoder = PytorchSeq2VecWrapper(nn.LSTM(word_embeddings.get_output_dim(), config.hidden_sz, bidirectional=True, batch_first=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QsgdLD-zraCB",
        "colab": {}
      },
      "source": [
        "model = BaselineModel(word_embeddings, encoder)\n",
        "\n",
        "if USE_GPU: model.cuda()\n",
        "else: model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c9h0Vmo0raCO"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0lBrE6U_raCP",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t31y1Lh-raCZ",
        "colab": {}
      },
      "source": [
        "from allennlp.training.trainer import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    iterator=iterator,\n",
        "    train_dataset=train_ds,\n",
        "    cuda_device=0 if USE_GPU else -1,\n",
        "    num_epochs=config.epochs,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fB45IOSfraCg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e9afa36f-d31c-48c8-d314-d6b3263846ed"
      },
      "source": [
        "metrics = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.6448 ||: 100%|██████████| 76/76 [01:00<00:00,  1.27it/s]\n",
            "loss: 0.6339 ||: 100%|██████████| 76/76 [01:02<00:00,  1.21it/s]\n",
            "loss: 0.6305 ||: 100%|██████████| 76/76 [01:07<00:00,  1.12it/s]\n",
            "loss: 0.6246 ||: 100%|██████████| 76/76 [01:07<00:00,  1.12it/s]\n",
            "loss: 0.6220 ||: 100%|██████████| 76/76 [01:07<00:00,  1.12it/s]\n",
            "loss: 0.6180 ||: 100%|██████████| 76/76 [01:07<00:00,  1.12it/s]\n",
            "loss: 0.6123 ||: 100%|██████████| 76/76 [01:07<00:00,  1.12it/s]\n",
            "loss: 0.6080 ||: 100%|██████████| 76/76 [01:07<00:00,  1.12it/s]\n",
            "loss: 0.6013 ||: 100%|██████████| 76/76 [01:08<00:00,  1.12it/s]\n",
            "loss: 0.5969 ||: 100%|██████████| 76/76 [01:07<00:00,  1.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MQF-AbNGsr_j"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_nLYjz8BssAM",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import DataIterator\n",
        "from tqdm import tqdm\n",
        "from scipy.special import expit # the sigmoid function\n",
        "\n",
        "def tonp(tsr): return tsr.detach().cpu().numpy()\n",
        "\n",
        "class Predictor:\n",
        "    def __init__(self, model: Model, iterator: DataIterator,\n",
        "                 cuda_device: int=-1) -> None:\n",
        "        self.model = model\n",
        "        self.iterator = iterator\n",
        "        self.cuda_device = cuda_device\n",
        "        \n",
        "    def _extract_data(self, batch) -> np.ndarray:\n",
        "        out_dict = self.model(**batch)\n",
        "        return expit(tonp(out_dict[\"class_logits\"]))\n",
        "    \n",
        "    def predict(self, ds: Iterable[Instance]) -> np.ndarray:\n",
        "        pred_generator = self.iterator(ds, num_epochs=1, shuffle=False)\n",
        "        self.model.eval()\n",
        "        pred_generator_tqdm = tqdm(pred_generator,\n",
        "                                   total=self.iterator.get_num_batches(ds))\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for batch in pred_generator_tqdm:\n",
        "                batch = nn_util.move_to_device(batch, self.cuda_device)\n",
        "                preds.append(self._extract_data(batch))\n",
        "        return np.concatenate(preds, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBkIHIjYsTww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import BasicIterator\n",
        "\n",
        "# iterate over the dataset without changing its order\n",
        "seq_iterator = BasicIterator(batch_size=64)\n",
        "seq_iterator.index_with(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHMW_6P3sY0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa192b26-2b63-4ea8-f6fb-cf9e6364ffb9"
      },
      "source": [
        "predictor = Predictor(model, seq_iterator, cuda_device=0 if USE_GPU else -1)\n",
        "test_preds = predictor.predict(test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 33/33 [00:34<00:00,  1.06s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYR_1IWrtWLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a541909-f807-4787-c537-5de6750b78e5"
      },
      "source": [
        "# Convert to predictions\n",
        "y_pred_bool = np.argmax(test_preds, axis=1)\n",
        "y_pred_bool[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 1, 0, 0, 2, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpYPOEZ2sccy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "33c346e4-2b1e-495e-fa92-85428fe2fa96"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "test_y = test_df[label]\n",
        "\n",
        "f1 = f1_score(test_y, y_pred_bool, average='weighted')\n",
        "print(f\"Best Test F1-Score: {f1:.3f}\")    \n",
        "print(classification_report(test_y, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Test F1-Score: 0.397\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.41      0.40       673\n",
            "           1       0.37      0.34      0.35       678\n",
            "           2       0.43      0.44      0.43       720\n",
            "\n",
            "    accuracy                           0.40      2071\n",
            "   macro avg       0.40      0.40      0.40      2071\n",
            "weighted avg       0.40      0.40      0.40      2071\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtCqEBEvUW3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_dir = '/content/gdrive/My Drive/Colab Notebooks/outputs/elmo/'  + params.get('exp') + '/' + now \n",
        "\n",
        "try:\n",
        "  os.mkdir(output_dir)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "from json import dumps\n",
        "\n",
        "with open(output_dir + '/params.json', 'w') as f:\n",
        "  f.write(dumps(params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bG0nFKV1x_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(output_dir + \"/model.th\", 'wb') as f:\n",
        "    torch.save(model.state_dict(), f)\n",
        "\n",
        "vocab.save_to_files(output_dir + \"/vocabulary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_YoUlF1U1mG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(output_dir + '/classification_report.txt', 'w') as f:\n",
        "  f.write(classification_report(test_y, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAvbKReHW-il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}