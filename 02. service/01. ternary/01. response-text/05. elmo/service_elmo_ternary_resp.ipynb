{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Allennlp ELMO BRWAC - Atendimento-Balanced-Multiclass-response.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaa8g26efCNu",
        "colab_type": "text"
      },
      "source": [
        "# Reference\n",
        "\n",
        "*   Original Tutorial: http://mlexplained.com/2019/01/30/an-in-depth-tutorial-to-allennlp-from-basics-to-elmo-and-bert/\n",
        "*   Original Colab: https://colab.research.google.com/github/dudeperf3ct/DL_notebooks/blob/master/tl_nlp/tl_nlp_allennlp.ipynb#scrollTo=pDBy4oPBOftc\n",
        "*   Modified ELMO Colab for text classification: https://github.com/keitakurita/Practical_NLP_in_PyTorch/blob/master/allennlp/elmo_text_classification.ipynb\n",
        "\n",
        "#### Other references:\n",
        "\n",
        "*   http://www.realworldnlpbook.com/blog/improving-sentiment-analyzer-using-elmo.html\n",
        "*   https://dudeperf3ct.github.io/nlp/transfer/learning/2019/02/22/Power-of-Transfer-Learning-in-NLP/#elmo\n",
        "*   https://allennlp.org/tutorials\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDBy4oPBOftc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "6a88d63c-8f85-4534-b769-c13e2bca4cfe"
      },
      "source": [
        "!pip install -q allennlp==0.8.2\n",
        "\n",
        "import allennlp\n",
        "allennlp.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.6MB 16.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 12.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 12.6MB 242kB/s \n",
            "\u001b[K     |████████████████████████████████| 317kB 59.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 59.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 552kB 59.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 68.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.2MB 130kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 51.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 62.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 512kB 64.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 5.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.5MB 49.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 60.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6MB 50.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 32.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9MB 50.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 53.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 66.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 13.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 40.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 13.7MB 238kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 54.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 67.4MB/s \n",
            "\u001b[?25h  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsondiff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.12.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.0.18 has requirement regex==2018.01.10, but you'll have regex 2019.12.20 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.2.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.10 has requirement dill>=0.3.2, but you'll have dill 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.2.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: awscli 1.18.128 has requirement botocore==1.17.51, but you'll have botocore 1.17.48 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.8.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSJJlBjOijHx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0ba7a2b3-3deb-4e75-8842-fc9622d3f385"
      },
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.0.18'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEEEik2gglSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97e90dc3-db90-4883-8938-ef0297c084d1"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.6.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbUhD7ZdgpSV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "686921b2-4262-4160-9672-41ac072972dd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Aug 31 11:55:24 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n2M5Xe8gsQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.set_device(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrHyuxNgRwXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "063ca067-9a4a-4155-8d4a-fd26a4000672"
      },
      "source": [
        "# https://spacy.io/models/pt\n",
        "\n",
        "! python -m spacy download pt\n",
        "! python -m spacy download pt_core_news_sm\n",
        "\n",
        "cur_language = 'pt_core_news_sm'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pt_core_news_sm==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz (38.7MB)\n",
            "\u001b[K     |████████████████████████████████| 38.7MB 737kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.0.0-cp36-none-any.whl size=38749345 sha256=387318138119d3a5c28d50f020b2208cdb6954a67f9025c8fabc46125839fb4c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dsg8srxu/wheels/0b/f1/54/a8f759b41cf39d2a33d6da84cd90b8e2fefea549963396bbd2\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "\n",
            "    You can now load the model via spacy.load('pt')\n",
            "\n",
            "Requirement already satisfied: pt_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz#egg=pt_core_news_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/pt_core_news_sm\n",
            "\n",
            "    You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrfKWMPPLjfc",
        "colab_type": "text"
      },
      "source": [
        "## e-SIC Dataset\n",
        "\n",
        "Code Adapted from : [Link](https://github.com/keitakurita/Practical_NLP_in_PyTorch)\n",
        "\n",
        "Paper ELMo : [Link](https://arxiv.org/pdf/1802.05365.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmROOTrsNK3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d069118-f6c4-42ee-b953-0e7681d32097"
      },
      "source": [
        "from pathlib import Path\n",
        "from typing import *\n",
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "from overrides import overrides\n",
        "\n",
        "from allennlp.data import Instance\n",
        "from allennlp.data.token_indexers import TokenIndexer\n",
        "from allennlp.data.tokenizers import Token\n",
        "from allennlp.nn import util as nn_util\n",
        "from allennlp.common.checks import ConfigurationError\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "print(USE_GPU)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lobzm4ENeRaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Variables\n",
        "params = {\n",
        "    'exp': 'Atendimento-Balanced-Multiclass',\n",
        "    'data': 'resp-text',\n",
        "    'label': 'Atendimento',\n",
        "    'BATCH_SIZE': 64,\n",
        "    'MAX_LEN': 128,\n",
        "    'lr': 3e-4,\n",
        "    'epochs': 10,\n",
        "    'hidden_sz': 64,\n",
        "    'max_vocab_size': 10000\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m3ZGpgfehio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7fc65c3a-5ecf-4856-f23b-66497a3be8a9"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Driver\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tocRrPaaUzTr",
        "colab": {}
      },
      "source": [
        "# Load Data\n",
        "binary = False\n",
        "exp = params.get('exp')\n",
        "if 'Binary' in exp:\n",
        "  binary = True\n",
        "\n",
        "base_path = '/content/gdrive/My Drive/Colab Notebooks/Simple/Datasets/' + exp\n",
        "save_path = '/content/gdrive/My Drive/Colab Notebooks/Simple/' + exp + '/output/'\n",
        "\n",
        "data = params.get('data')\n",
        "label = params.get('label')\n",
        "\n",
        "x_train_file = 'X_train.csv'\n",
        "y_train_file = 'y_train.csv'\n",
        "x_test_file = 'X_test.csv'\n",
        "y_test_file = 'y_test.csv'\n",
        "\n",
        "#Load data\n",
        "X_train = pd.read_csv(os.path.join(base_path, x_train_file), sep=';', encoding='utf-8')\n",
        "y_train = pd.read_csv(os.path.join(base_path, y_train_file), sep=';', encoding='utf-8')\n",
        "X_test = pd.read_csv(os.path.join(base_path, x_test_file), sep=';', encoding='utf-8')\n",
        "y_test = pd.read_csv(os.path.join(base_path, y_test_file), sep=';', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7vOfU5_eS5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "9a864cf7-b078-4038-8bb7-25e24ae7e594"
      },
      "source": [
        "#df = pd.concat([X_train, X_test], axis=0)\n",
        "train_df = X_train.loc[:,['pid', data, label]]\n",
        "test_df = X_test.loc[:,['pid', data, label]]\n",
        "\n",
        "train_df['positive'] = train_df.apply(lambda row: 1 if row[label] == 2 else 0, axis=1)\n",
        "train_df['negative'] = train_df.apply(lambda row: 1 if row[label] == 0 else 0, axis=1)\n",
        "train_df['neutral'] = train_df.apply(lambda row: 1 if row[label] == 1 else 0, axis=1)\n",
        "\n",
        "test_df['positive'] = test_df.apply(lambda row: 1 if row[label] == 2 else 0, axis=1)\n",
        "test_df['negative'] = test_df.apply(lambda row: 1 if row[label] == 0 else 0, axis=1)\n",
        "test_df['neutral'] = test_df.apply(lambda row: 1 if row[label] == 1 else 0, axis=1)\n",
        "\n",
        "train_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pid</th>\n",
              "      <th>resp-text</th>\n",
              "      <th>Atendimento</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>529374</td>\n",
              "      <td>Prezado Senhor , Em consideração a sua manifes...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>517464</td>\n",
              "      <td>Prezado a Senhor a , Em atendimento ao pedido ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>406897</td>\n",
              "      <td>Prezado , Ao cumprimentá-lo cordialmente , inf...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>388221</td>\n",
              "      <td>Prezado Senhor , Em atenção à sua demanda regi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>451583</td>\n",
              "      <td>Prezado Sr . Yuri , boa tarde , Em atenção a s...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>505170</td>\n",
              "      <td>Prezado , Segue resposta da Diretoria de Estud...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>354638</td>\n",
              "      <td>Respondente : Serviço de Informação ao Cidadã...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>526968</td>\n",
              "      <td>Prezado senhor , Conforme informações prestada...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>552107</td>\n",
              "      <td>Boa tarde , Recebemos , da Pró-Reitoria de Ges...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>403296</td>\n",
              "      <td>Senhor Gutemberg , O Serviço de Informações ao...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      pid                                          resp-text  ...  negative  neutral\n",
              "0  529374  Prezado Senhor , Em consideração a sua manifes...  ...         0        1\n",
              "1  517464  Prezado a Senhor a , Em atendimento ao pedido ...  ...         0        1\n",
              "2  406897  Prezado , Ao cumprimentá-lo cordialmente , inf...  ...         1        0\n",
              "3  388221  Prezado Senhor , Em atenção à sua demanda regi...  ...         1        0\n",
              "4  451583  Prezado Sr . Yuri , boa tarde , Em atenção a s...  ...         0        1\n",
              "5  505170  Prezado , Segue resposta da Diretoria de Estud...  ...         0        1\n",
              "6  354638   Respondente : Serviço de Informação ao Cidadã...  ...         0        0\n",
              "7  526968  Prezado senhor , Conforme informações prestada...  ...         0        0\n",
              "8  552107  Boa tarde , Recebemos , da Pró-Reitoria de Ges...  ...         0        1\n",
              "9  403296  Senhor Gutemberg , O Serviço de Informações ao...  ...         0        0\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu5wUlQ5kTxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "1d634cae-ce2e-4007-a5d5-2a8bfb8103f2"
      },
      "source": [
        "test_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pid</th>\n",
              "      <th>resp-text</th>\n",
              "      <th>Atendimento</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>514368</td>\n",
              "      <td>Prezado senhor esclarecemos que Susep não poss...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>452197</td>\n",
              "      <td>Com relação ao pedido de informação de protoc...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>533396</td>\n",
              "      <td>Prezado Senhor , Em atenção seu pedido formula...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>567521</td>\n",
              "      <td>Prezada solicitante , Segue , em anexo , respo...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>295701</td>\n",
              "      <td>Senhor Bernardo, O Serviço de Informações ao C...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>478858</td>\n",
              "      <td>Prezado Pedro , A publicação é feita nas segui...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>562079</td>\n",
              "      <td>Prezada Senhora , boa tarde ! Em atenção à su...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>393850</td>\n",
              "      <td>Prezada Senhora GiovannaTrevizan Benigno , Rec...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>533823</td>\n",
              "      <td>Segue anexo resposta à solicitação de informaç...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>497668</td>\n",
              "      <td>Senhor Rodrigo , O Serviço de Informações ao C...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      pid                                          resp-text  ...  negative  neutral\n",
              "0  514368  Prezado senhor esclarecemos que Susep não poss...  ...         0        1\n",
              "1  452197   Com relação ao pedido de informação de protoc...  ...         0        1\n",
              "2  533396  Prezado Senhor , Em atenção seu pedido formula...  ...         0        1\n",
              "3  567521  Prezada solicitante , Segue , em anexo , respo...  ...         0        0\n",
              "4  295701  Senhor Bernardo, O Serviço de Informações ao C...  ...         0        1\n",
              "5  478858  Prezado Pedro , A publicação é feita nas segui...  ...         0        0\n",
              "6  562079   Prezada Senhora , boa tarde ! Em atenção à su...  ...         0        1\n",
              "7  393850  Prezada Senhora GiovannaTrevizan Benigno , Rec...  ...         0        1\n",
              "8  533823  Segue anexo resposta à solicitação de informaç...  ...         0        1\n",
              "9  497668  Senhor Rodrigo , O Serviço de Informações ao C...  ...         0        0\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ6GJQP2amGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  os.mkdir('data/')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "train_df.to_csv('data/train_df.csv', index=False)\n",
        "test_df.to_csv('data/test_df.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWJVOsTHNO74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "        \n",
        "config = Config(\n",
        "    testing=False,\n",
        "    seed=1,\n",
        "    batch_size=params.get('BATCH_SIZE'),\n",
        "    lr=params.get('lr'),\n",
        "    epochs=params.get('epochs'),\n",
        "    hidden_sz=params.get('hidden_sz'),\n",
        "    max_seq_len=params.get('MAX_LEN'), # necessary to limit memory usage\n",
        "    max_vocab_size=params.get('max_vocab_size'),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWEsfzKbNPEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(config.seed)\n",
        "DATA_ROOT = Path(\"data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ux5_-oyTld1",
        "colab_type": "text"
      },
      "source": [
        "### Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97kO5UV5NPKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.data.dataset_readers import DatasetReader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEFPAZf7NPM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_cols = [\"negative\", \"neutral\", \"positive\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgTrDjOkPcED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.fields import TextField, MetadataField, ArrayField\n",
        "\n",
        "class SentimentDatasetReader(DatasetReader):\n",
        "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
        "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
        "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
        "        super().__init__(lazy=False)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    @overrides\n",
        "    def text_to_instance(self, tokens: List[Token], id: str=None, labels: np.ndarray=None) -> Instance:\n",
        "        sentence_field = TextField(tokens, self.token_indexers)\n",
        "        fields = {\"tokens\": sentence_field}\n",
        "        \n",
        "        id_field = MetadataField(id)\n",
        "        fields[\"id\"] = id_field\n",
        "        \n",
        "        if labels is None:\n",
        "            labels = np.zeros(len(label_cols))\n",
        "        label_field = ArrayField(array=labels)\n",
        "        fields[\"label\"] = label_field\n",
        "\n",
        "        return Instance(fields)\n",
        "    \n",
        "    @overrides\n",
        "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
        "        df = pd.read_csv(file_path)\n",
        "        if config.testing: df = df.head(1000)\n",
        "        for i, row in df.iterrows():\n",
        "            yield self.text_to_instance([Token(x) for x in self.tokenizer(row[data])], None, row[label_cols].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Po9wuzw-rZ9x"
      },
      "source": [
        "## ELMo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cU-g0PQ-rZ9_",
        "colab": {}
      },
      "source": [
        "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
        "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n",
        "\n",
        "# the token indexer is responsible for mapping tokens to integers\n",
        "token_indexer = ELMoTokenCharactersIndexer()\n",
        "\n",
        "def tokenizer(x: str):\n",
        "    return [w.text for w in SpacyWordSplitter(language=cur_language, pos_tags=False).split_words(x)[:config.max_seq_len]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s8p-gJ-9rZ-P",
        "colab": {}
      },
      "source": [
        "reader = SentimentDatasetReader(\n",
        "    tokenizer=tokenizer,\n",
        "    token_indexers={\"tokens\": token_indexer}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fX3yQmXurZ-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "31dcd7fc-9666-4ca0-a43f-b04a5336cfd0"
      },
      "source": [
        "train_ds = reader.read(DATA_ROOT / \"train_df.csv\")\n",
        "print(len(train_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6982it [00:19, 365.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hrDWynosqme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a2c5b8c-9ee1-4f5b-d6b1-72d364d08d00"
      },
      "source": [
        "test_ds = reader.read(DATA_ROOT / \"test_df.csv\")\n",
        "print(len(test_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2993it [00:07, 394.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovgOH85rqC0J",
        "colab_type": "text"
      },
      "source": [
        "### Checking Tokens & Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0KqdOBUZrZ-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52373f7c-8236-4418-d146-d25d9760f438"
      },
      "source": [
        "vars(train_ds[0].fields[\"tokens\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_indexed_tokens': None,\n",
              " '_indexer_name_to_indexed_token': None,\n",
              " '_token_indexers': {'tokens': <allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer at 0x7f5e6d09e4e0>},\n",
              " 'tokens': [Prezado,\n",
              "  Senhor,\n",
              "  ,,\n",
              "  Em,\n",
              "  consideração,\n",
              "  a,\n",
              "  sua,\n",
              "  manifestação,\n",
              "  registrada,\n",
              "  no,\n",
              "  e,\n",
              "  -,\n",
              "  SIC,\n",
              "  ,,\n",
              "  protocolo,\n",
              "  número,\n",
              "  53850000689201784,\n",
              "  ,,\n",
              "  informamos,\n",
              "  que,\n",
              "  este,\n",
              "  não,\n",
              "  é,\n",
              "  o,\n",
              "  meio,\n",
              "  adequado,\n",
              "  para,\n",
              "  Vossa,\n",
              "  Senhoria,\n",
              "  solicitar,\n",
              "  recebimento,\n",
              "  de,\n",
              "  senha,\n",
              "  do,\n",
              "  CADSEI,\n",
              "  .,\n",
              "  Por,\n",
              "  oportuno,\n",
              "  ,,\n",
              "  identificamos,\n",
              "  que,\n",
              "  Vossa,\n",
              "  Senhoria,\n",
              "  também,\n",
              "  registrou,\n",
              "  no,\n",
              "  Sistema,\n",
              "  de,\n",
              "  Ouvidorias,\n",
              "  do,\n",
              "  Poder,\n",
              "  Executivo,\n",
              "  Federal,\n",
              "  e,\n",
              "  -,\n",
              "  Ouv,\n",
              "  uma,\n",
              "  demanda,\n",
              "  com,\n",
              "  o,\n",
              "  mesmo,\n",
              "  teor,\n",
              "  ,,\n",
              "  através,\n",
              "  do,\n",
              "  protocolo,\n",
              "  número,\n",
              "  01217,\n",
              "  .,\n",
              "  003492,\n",
              "  2017,\n",
              "  -,\n",
              "  79,\n",
              "  ,,\n",
              "  que,\n",
              "  n,\n",
              "  este,\n",
              "  momento,\n",
              "  reiteramos,\n",
              "  as,\n",
              "  orientações,\n",
              "  contidas,\n",
              "  naresposta,\n",
              "  enviada,\n",
              "  .,\n",
              "  O,\n",
              "  Ministério,\n",
              "  agradece,\n",
              "  o,\n",
              "  seu,\n",
              "  contato,\n",
              "  .,\n",
              "  Atenciosamente,\n",
              "  ,,\n",
              "  Serviço,\n",
              "  de,\n",
              "  Informações,\n",
              "  a,\n",
              "  o,\n",
              "  Cidadão,\n",
              "  -,\n",
              "  SIC,\n",
              "  Ministério,\n",
              "  da,\n",
              "  Ciência,\n",
              "  ,,\n",
              "  Tecnologia,\n",
              "  ,,\n",
              "  Inovações,\n",
              "  e,\n",
              "  Comunicações,\n",
              "  MCTIC]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N6lwAUZjrZ_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88f852f5-1bda-4602-eb03-161188bef566"
      },
      "source": [
        "vars(train_ds[0].fields[\"label\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'array': array([0, 1, 0], dtype=object), 'padding_value': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t1TFE9kvrZ_O"
      },
      "source": [
        "### Prepare Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TsN2VpKSrZ_T",
        "colab": {}
      },
      "source": [
        "vocab = Vocabulary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZSDayQsgrZ_g"
      },
      "source": [
        "### Prepare Iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vc7kgux6rZ_p",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import BucketIterator\n",
        "\n",
        "iterator = BucketIterator(batch_size=config.batch_size, sorting_keys=[(\"tokens\", \"num_tokens\")],)\n",
        "iterator.index_with(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aXuusjbgraA1"
      },
      "source": [
        "### Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zl1OCBVEraA_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a8aababd-fef6-4c63-9b02-a8f803dcd8d6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
        "from allennlp.nn.util import get_text_field_mask\n",
        "from allennlp.models import Model\n",
        "from allennlp.modules.text_field_embedders import TextFieldEmbedder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QoexCIfmraBM",
        "colab": {}
      },
      "source": [
        "class BaselineModel(Model):\n",
        "    def __init__(self, word_embeddings: TextFieldEmbedder,\n",
        "                 encoder: Seq2VecEncoder,\n",
        "                 out_sz: int=len(label_cols)):\n",
        "        super().__init__(vocab)\n",
        "        self.word_embeddings = word_embeddings\n",
        "        self.encoder = encoder\n",
        "        self.projection = nn.Linear(self.encoder.get_output_dim(), out_sz)\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "        \n",
        "    def forward(self, tokens: Dict[str, torch.Tensor],\n",
        "                id: Any, label: torch.Tensor) -> torch.Tensor:\n",
        "        mask = get_text_field_mask(tokens)\n",
        "        embeddings = self.word_embeddings(tokens)\n",
        "        state = self.encoder(embeddings, mask)\n",
        "        class_logits = self.projection(state)\n",
        "        \n",
        "        output = {\"class_logits\": class_logits}\n",
        "        output[\"loss\"] = self.loss(class_logits, label)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t-RIhCDvraBb"
      },
      "source": [
        "### Prepare Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ng3lzsNMraBf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b4da671-42f3-4f3b-b30b-9ee3c2fe6dd6"
      },
      "source": [
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
        "\n",
        "# https://allennlp.org/elmo - PORTUGUESE BRWAC\n",
        "options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/contributed/pt/brwac/options.json'\n",
        "weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/contributed/pt/brwac/elmo_pt_weights_dgx1.hdf5'\n",
        "\n",
        "elmo_embedder = ElmoTokenEmbedder(options_file, weight_file)\n",
        "word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 547/547 [00:00<00:00, 506352.75B/s]\n",
            "100%|██████████| 374434792/374434792 [00:27<00:00, 13397153.47B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZAbX3qNtraBx",
        "colab": {}
      },
      "source": [
        "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
        "\n",
        "# Create Encoder\n",
        "encoder: Seq2VecEncoder = PytorchSeq2VecWrapper(nn.LSTM(word_embeddings.get_output_dim(), config.hidden_sz, bidirectional=True, batch_first=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QsgdLD-zraCB",
        "colab": {}
      },
      "source": [
        "model = BaselineModel(word_embeddings, encoder)\n",
        "\n",
        "if USE_GPU: model.cuda()\n",
        "else: model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c9h0Vmo0raCO"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0lBrE6U_raCP",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t31y1Lh-raCZ",
        "colab": {}
      },
      "source": [
        "from allennlp.training.trainer import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    iterator=iterator,\n",
        "    train_dataset=train_ds,\n",
        "    cuda_device=0 if USE_GPU else -1,\n",
        "    num_epochs=config.epochs,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fB45IOSfraCg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "81057a20-7248-41a9-b2e0-1ad641cca0e1"
      },
      "source": [
        "metrics = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.6419 ||: 100%|██████████| 110/110 [01:22<00:00,  1.33it/s]\n",
            "loss: 0.6308 ||: 100%|██████████| 110/110 [01:25<00:00,  1.29it/s]\n",
            "loss: 0.6258 ||: 100%|██████████| 110/110 [01:27<00:00,  1.26it/s]\n",
            "loss: 0.6202 ||: 100%|██████████| 110/110 [01:27<00:00,  1.26it/s]\n",
            "loss: 0.6162 ||: 100%|██████████| 110/110 [01:27<00:00,  1.26it/s]\n",
            "loss: 0.6107 ||: 100%|██████████| 110/110 [01:27<00:00,  1.26it/s]\n",
            "loss: 0.6069 ||: 100%|██████████| 110/110 [01:27<00:00,  1.26it/s]\n",
            "loss: 0.6015 ||: 100%|██████████| 110/110 [01:27<00:00,  1.26it/s]\n",
            "loss: 0.5961 ||: 100%|██████████| 110/110 [01:27<00:00,  1.26it/s]\n",
            "loss: 0.5922 ||: 100%|██████████| 110/110 [01:27<00:00,  1.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MQF-AbNGsr_j"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_nLYjz8BssAM",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import DataIterator\n",
        "from tqdm import tqdm\n",
        "from scipy.special import expit # the sigmoid function\n",
        "\n",
        "def tonp(tsr): return tsr.detach().cpu().numpy()\n",
        "\n",
        "class Predictor:\n",
        "    def __init__(self, model: Model, iterator: DataIterator,\n",
        "                 cuda_device: int=-1) -> None:\n",
        "        self.model = model\n",
        "        self.iterator = iterator\n",
        "        self.cuda_device = cuda_device\n",
        "        \n",
        "    def _extract_data(self, batch) -> np.ndarray:\n",
        "        out_dict = self.model(**batch)\n",
        "        return expit(tonp(out_dict[\"class_logits\"]))\n",
        "    \n",
        "    def predict(self, ds: Iterable[Instance]) -> np.ndarray:\n",
        "        pred_generator = self.iterator(ds, num_epochs=1, shuffle=False)\n",
        "        self.model.eval()\n",
        "        pred_generator_tqdm = tqdm(pred_generator,\n",
        "                                   total=self.iterator.get_num_batches(ds))\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for batch in pred_generator_tqdm:\n",
        "                batch = nn_util.move_to_device(batch, self.cuda_device)\n",
        "                preds.append(self._extract_data(batch))\n",
        "        return np.concatenate(preds, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBkIHIjYsTww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import BasicIterator\n",
        "\n",
        "# iterate over the dataset without changing its order\n",
        "seq_iterator = BasicIterator(batch_size=64)\n",
        "seq_iterator.index_with(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHMW_6P3sY0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e529b9cb-37d8-456d-ac2c-b71505512a6b"
      },
      "source": [
        "predictor = Predictor(model, seq_iterator, cuda_device=0 if USE_GPU else -1)\n",
        "test_preds = predictor.predict(test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 47/47 [00:43<00:00,  1.09it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYR_1IWrtWLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6be38615-3cd2-4b43-dc33-32badf5dbb07"
      },
      "source": [
        "# Convert to predictions\n",
        "y_pred_bool = np.argmax(test_preds, axis=1)\n",
        "y_pred_bool[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1, 2, 1, 0, 0, 0, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpYPOEZ2sccy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "22adffc8-8848-42fe-8991-5a7039a61401"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "test_y = test_df[label]\n",
        "\n",
        "f1 = f1_score(test_y, y_pred_bool, average='weighted')\n",
        "print(f\"Best Test F1-Score: {f1:.3f}\")    \n",
        "print(classification_report(test_y, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Test F1-Score: 0.388\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.49      0.44       958\n",
            "           1       0.35      0.19      0.25      1006\n",
            "           2       0.44      0.53      0.48      1029\n",
            "\n",
            "    accuracy                           0.40      2993\n",
            "   macro avg       0.39      0.40      0.39      2993\n",
            "weighted avg       0.39      0.40      0.39      2993\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bG0nFKV1x_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_dir = '/content/gdrive/My Drive/Colab Notebooks/outputs/elmo/'  + params.get('exp') + '/' + now \n",
        "\n",
        "try:\n",
        "  os.mkdir(output_dir)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "from json import dumps\n",
        "\n",
        "with open(output_dir + '/params.json', 'w') as f:\n",
        "  f.write(dumps(params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcH4DaGJV_ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(output_dir + \"/model.th\", 'wb') as f:\n",
        "    torch.save(model.state_dict(), f)\n",
        "\n",
        "vocab.save_to_files(output_dir + \"/vocabulary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tg5GPiQWACn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(output_dir + '/classification_report.txt', 'w') as f:\n",
        "  f.write(classification_report(test_y, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}