{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliares\n",
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from json import dumps\n",
    "\n",
    "#Dados\n",
    "import pandas as pd\n",
    "\n",
    "#preprocessing and transformation\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "#Machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pid', 'req-text', 'resp-text', '1funct-request', '2pronoun-request',\n",
      "       '3ppron-request', '4i-request', '5we-request', '6you-request',\n",
      "       '7shehe-request',\n",
      "       ...\n",
      "       '58home-response', '59money-response', '60relig-response',\n",
      "       '61death-response', '62assent-response', '63nonfl-response',\n",
      "       '64filler-response', 'Clareza', 'Atendimento', 'tempo_resposta'],\n",
      "      dtype='object', length=134)\n",
      "(6982, 134)\n",
      "0    2367\n",
      "1    2319\n",
      "2    2296\n",
      "Name: Atendimento, dtype: int64\n",
      "2    1029\n",
      "1    1006\n",
      "0     958\n",
      "Name: Atendimento, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Variables\n",
    "base_path = 'D:/03. Documentos/Mestrado/22032020 - Experimentos/05. Organizado/03. Datasets/Atendimento-Balanced-Multiclass'\n",
    "save_path = 'output'\n",
    "\n",
    "data='req-text'\n",
    "label='Atendimento'\n",
    "\n",
    "x_train_file = 'X_train.csv'\n",
    "y_train_file = 'y_train.csv'\n",
    "x_test_file = 'X_test.csv'\n",
    "y_test_file = 'y_test.csv'\n",
    "\n",
    "#Load data\n",
    "X_train = pd.read_csv(os.path.join(base_path, x_train_file), sep=';', encoding='ansi')\n",
    "y_train = pd.read_csv(os.path.join(base_path, y_train_file), sep=';', encoding='ansi')\n",
    "X_test = pd.read_csv(os.path.join(base_path, x_test_file), sep=';', encoding='ansi')\n",
    "y_test = pd.read_csv(os.path.join(base_path, y_test_file), sep=';', encoding='ansi')\n",
    "\n",
    "#Checking on data\n",
    "print(X_train.columns)\n",
    "print(X_train.shape)\n",
    "print(y_train.Atendimento.value_counts())\n",
    "print(y_test.Atendimento.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline and GridSearch CV\n",
    "\n",
    "params = {\n",
    "    'vect_analyzer': 'word',\n",
    "    'vect_max_features': None,\n",
    "    'vect_min_df': 1,\n",
    "    'vect_max_df': 0.75,\n",
    "    'vect_ngram_range': (1,2),\n",
    "    'tfidf_use_idf': True,\n",
    "    'tf_idf_norm': 'l2',\n",
    "    'clf_solver':'lbfgs',\n",
    "    'clf_max_iter': 10000,\n",
    "    'clf_C': 0.1,\n",
    "    'gs_cv': 10,\n",
    "    'gs_scoring': 'f1_macro'   \n",
    "}\n",
    "\n",
    "pipelineWord = Pipeline([\n",
    "    ('vect',   CountVectorizer(analyzer=params.get('vect_analyzer'),\n",
    "                               max_features=params.get('vect_max_features'),\n",
    "                               min_df=params.get('vect_min_df'),\n",
    "                               max_df=params.get('vect_max_df'),\n",
    "                               ngram_range=params.get('vect_ngram_range'))),\n",
    "    \n",
    "    ('tfidf', TfidfTransformer(use_idf=params.get('tfidf_use_idf'),\n",
    "                               norm=params.get('tf_idf_norm'))),\n",
    "    \n",
    "    ('scaler', MaxAbsScaler()),\n",
    "    \n",
    "    ('clf', LogisticRegression(random_state=seed,\n",
    "                               n_jobs=6,\n",
    "                               C=params.get('clf_C'),\n",
    "                               solver=params.get('clf_solver'),\n",
    "                               max_iter=params.get('clf_max_iter')))\n",
    "])\n",
    "\n",
    "gs_parameters = {\n",
    "    #'vect__min_df': (1, 0.1, 0.25),\n",
    "    #'vect__max_df': (1.0, 0.75),\n",
    "    #'clf__C': (0.1, 1, 10, 100)\n",
    "}\n",
    "\n",
    "# Define grid search\n",
    "grid_search_word = GridSearchCV(pipelineWord,\n",
    "                               gs_parameters,\n",
    "                               cv=params.get('gs_cv'),\n",
    "                               scoring=params.get('gs_scoring'),\n",
    "                               n_jobs=6,\n",
    "                               verbose=10\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train[data]\n",
    "Y = y_train[label]\n",
    "x = X_test[data]\n",
    "y = y_test[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de características extraídas:\n",
      "\n",
      "(2993, 118264)\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade de características extraídas:\\n')\n",
    "print(CountVectorizer(analyzer=params.get('vect_analyzer'),\n",
    "                               max_features=params.get('vect_max_features'),\n",
    "                               min_df=params.get('vect_min_df'),\n",
    "                               max_df=params.get('vect_max_df'),\n",
    "                               ngram_range=params.get('vect_ngram_range')).fit_transform(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando Gridsearch para Solicitacoes - Multiclass WORD - Classe Atendimento\n",
      "2020_05_19_23_22_47\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   3 out of  10 | elapsed:   21.5s remaining:   50.4s\n",
      "[Parallel(n_jobs=6)]: Done   5 out of  10 | elapsed:   21.8s remaining:   21.8s\n",
      "[Parallel(n_jobs=6)]: Done   7 out of  10 | elapsed:   34.7s remaining:   14.8s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:   35.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 43.381s\n",
      "Best score: 0.446\n",
      "Best parameters set:\n"
     ]
    }
   ],
   "source": [
    "print(\"Executando Gridsearch para Solicitacoes - Multiclass WORD - Classe Atendimento\")\n",
    "\n",
    "now = str(datetime.now()).split('.')[0].replace('-', '_').replace(' ', '_').replace(':', '_')\n",
    "print(now)\n",
    "\n",
    "t0 = time()\n",
    "grid_search_word.fit(X, Y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print(\"Best score: %0.3f\" % grid_search_word.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search_word.best_estimator_.get_params()\n",
    "for param_name in sorted(gs_parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "f_save = now + '_Atendimento_Solicitacao_Multiclass_Balanced_word.sav'\n",
    "pickle.dump(grid_search_word, open(os.path.join(save_path, f_save),'wb'))\n",
    "\n",
    "# Saving Parameters\n",
    "with open(os.path.join(save_path, 'params.txt'),'a') as f:\n",
    "    f.write('\\n\\n' + ('#'*60))\n",
    "    f.write('\\n'+f_save + '\\n\\n')\n",
    "    f.write('Parameters:\\n')\n",
    "    f.write(dumps(params) + '\\n')\n",
    "    f.write('\\nGridSearch Best Parameters:\\n')\n",
    "    for param_name in sorted(gs_parameters.keys()):        \n",
    "        f.write(\"%s: %r\" % (param_name, best_parameters[param_name]) + '\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred_train = grid_search_word.predict(X)\n",
    "y_pred_test = grid_search_word.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "Report for TRAIN\n",
      "##################################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      2367\n",
      "           1       0.96      0.96      0.96      2319\n",
      "           2       0.95      0.97      0.96      2296\n",
      "\n",
      "    accuracy                           0.97      6982\n",
      "   macro avg       0.97      0.97      0.97      6982\n",
      "weighted avg       0.97      0.97      0.97      6982\n",
      "\n",
      "##################################################\n",
      "Report for TEST\n",
      "##################################################\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.47      0.45       958\n",
      "           1       0.41      0.41      0.41      1006\n",
      "           2       0.50      0.45      0.47      1029\n",
      "\n",
      "    accuracy                           0.44      2993\n",
      "   macro avg       0.44      0.44      0.44      2993\n",
      "weighted avg       0.45      0.44      0.44      2993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('#'*50)\n",
    "print('Report for TRAIN')\n",
    "print('#'*50)\n",
    "print(classification_report(Y, y_pred_train))\n",
    "\n",
    "print('#'*50)\n",
    "print('Report for TEST')\n",
    "print('#'*50)\n",
    "print(classification_report(y, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path, 'params.txt'),'a') as f:\n",
    "    f.write('\\n\\n' + ('#'*60))\n",
    "    f.write('\\nReport for TRAIN')\n",
    "    f.write('\\n' + ('#'*60))\n",
    "    f.write('\\n' + classification_report(Y, y_pred_train))\n",
    "    \n",
    "    f.write('\\n\\n' + ('#'*60))\n",
    "    f.write('\\nReport for TEST')\n",
    "    f.write('\\n' + ('#'*60))\n",
    "    f.write('\\n' + classification_report(y, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
