{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Allennlp ELMO BRWAC - Atendimento-Balanced-Multiclass-req.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ovgOH85rqC0J",
        "t1TFE9kvrZ_O",
        "ZSDayQsgrZ_g"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaa8g26efCNu",
        "colab_type": "text"
      },
      "source": [
        "# Reference\n",
        "\n",
        "*   Original Tutorial: http://mlexplained.com/2019/01/30/an-in-depth-tutorial-to-allennlp-from-basics-to-elmo-and-bert/\n",
        "*   Original Colab: https://colab.research.google.com/github/dudeperf3ct/DL_notebooks/blob/master/tl_nlp/tl_nlp_allennlp.ipynb#scrollTo=pDBy4oPBOftc\n",
        "*   Modified ELMO Colab for text classification: https://github.com/keitakurita/Practical_NLP_in_PyTorch/blob/master/allennlp/elmo_text_classification.ipynb\n",
        "\n",
        "#### Other references:\n",
        "\n",
        "*   http://www.realworldnlpbook.com/blog/improving-sentiment-analyzer-using-elmo.html\n",
        "*   https://dudeperf3ct.github.io/nlp/transfer/learning/2019/02/22/Power-of-Transfer-Learning-in-NLP/#elmo\n",
        "*   https://allennlp.org/tutorials\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDBy4oPBOftc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "outputId": "af901608-5068-44e2-e9c4-3d521711a816"
      },
      "source": [
        "!pip install -q allennlp==0.8.2\n",
        "\n",
        "import allennlp\n",
        "allennlp.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.6MB 8.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.2MB 128kB/s \n",
            "\u001b[K     |████████████████████████████████| 4.5MB 49.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 43.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 51.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 552kB 49.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 12.6MB 134kB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 60.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 12.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 317kB 43.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 512kB 54.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 49.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 58.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 614kB 45.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9MB 43.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 60.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 11.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6MB 44.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 57.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6MB 44.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 57.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 41.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 52.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 13.7MB 236kB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 60.7MB/s \n",
            "\u001b[?25h  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsondiff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement wrapt>=1.11.1, but you'll have wrapt 1.10.11 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.2.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.10 has requirement dill>=0.3.2, but you'll have dill 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 2.2.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.8.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSJJlBjOijHx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "270133a5-36cc-41d6-baec-83f674b28cc2"
      },
      "source": [
        "import spacy\n",
        "spacy.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.0.18'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEEEik2gglSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c02d1b6e-ae77-48f5-cbe8-6cb3b0dd3742"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.6.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbUhD7ZdgpSV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "8e46983f-41fe-414f-9d93-0bc25776581b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Aug 31 12:45:51 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n2M5Xe8gsQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.set_device(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrHyuxNgRwXV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "553e6e81-7c67-42e8-dc16-025f7722e779"
      },
      "source": [
        "# https://spacy.io/models/pt\n",
        "\n",
        "! python -m spacy download pt\n",
        "! python -m spacy download pt_core_news_sm\n",
        "\n",
        "cur_language = 'pt_core_news_sm'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pt_core_news_sm==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz (38.7MB)\n",
            "\u001b[K     |████████████████████████████████| 38.7MB 1.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.0.0-cp36-none-any.whl size=38749345 sha256=544bda03b2ec556d93311a4edeee5b275d09bd87002569498909417f7e6102ab\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2k69opo9/wheels/0b/f1/54/a8f759b41cf39d2a33d6da84cd90b8e2fefea549963396bbd2\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "\n",
            "    You can now load the model via spacy.load('pt')\n",
            "\n",
            "Requirement already satisfied: pt_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.0.0/pt_core_news_sm-2.0.0.tar.gz#egg=pt_core_news_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/pt_core_news_sm\n",
            "\n",
            "    You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrfKWMPPLjfc",
        "colab_type": "text"
      },
      "source": [
        "## e-SIC Dataset\n",
        "\n",
        "Code Adapted from : [Link](https://github.com/keitakurita/Practical_NLP_in_PyTorch)\n",
        "\n",
        "Paper ELMo : [Link](https://arxiv.org/pdf/1802.05365.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmROOTrsNK3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2064ef92-6f68-4d75-b6a2-52db81a6c2ed"
      },
      "source": [
        "from pathlib import Path\n",
        "from typing import *\n",
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "from overrides import overrides\n",
        "\n",
        "from allennlp.data import Instance\n",
        "from allennlp.data.token_indexers import TokenIndexer\n",
        "from allennlp.data.tokenizers import Token\n",
        "from allennlp.nn import util as nn_util\n",
        "from allennlp.common.checks import ConfigurationError\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "print(USE_GPU)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lobzm4ENeRaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Variables\n",
        "params = {\n",
        "    'exp': 'Atendimento-Balanced-Multiclass',\n",
        "    'data': 'req-text',\n",
        "    'label': 'Atendimento',\n",
        "    'BATCH_SIZE': 64,\n",
        "    'MAX_LEN': 128,\n",
        "    'lr': 3e-4,\n",
        "    'epochs': 10,\n",
        "    'hidden_sz': 64,\n",
        "    'max_vocab_size': 10000\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m3ZGpgfehio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f48f4077-cf0c-4cc0-fc7a-a7da007409f4"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Driver\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tocRrPaaUzTr",
        "colab": {}
      },
      "source": [
        "# Load Data\n",
        "binary = False\n",
        "exp = params.get('exp')\n",
        "if 'Binary' in exp:\n",
        "  binary = True\n",
        "\n",
        "base_path = '/content/gdrive/My Drive/Colab Notebooks/Simple/Datasets/' + exp\n",
        "save_path = '/content/gdrive/My Drive/Colab Notebooks/Simple/' + exp + '/output/'\n",
        "\n",
        "data = params.get('data')\n",
        "label = params.get('label')\n",
        "\n",
        "x_train_file = 'X_train.csv'\n",
        "y_train_file = 'y_train.csv'\n",
        "x_test_file = 'X_test.csv'\n",
        "y_test_file = 'y_test.csv'\n",
        "\n",
        "#Load data\n",
        "X_train = pd.read_csv(os.path.join(base_path, x_train_file), sep=';', encoding='utf-8')\n",
        "y_train = pd.read_csv(os.path.join(base_path, y_train_file), sep=';', encoding='utf-8')\n",
        "X_test = pd.read_csv(os.path.join(base_path, x_test_file), sep=';', encoding='utf-8')\n",
        "y_test = pd.read_csv(os.path.join(base_path, y_test_file), sep=';', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7vOfU5_eS5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "460f3d1d-8d81-466f-ccde-385a9abda83a"
      },
      "source": [
        "#df = pd.concat([X_train, X_test], axis=0)\n",
        "train_df = X_train.loc[:,['pid', data, label]]\n",
        "test_df = X_test.loc[:,['pid', data, label]]\n",
        "\n",
        "train_df['positive'] = train_df.apply(lambda row: 1 if row['Atendimento'] == 2 else 0, axis=1)\n",
        "train_df['negative'] = train_df.apply(lambda row: 1 if row['Atendimento'] == 0 else 0, axis=1)\n",
        "train_df['neutral'] = train_df.apply(lambda row: 1 if row['Atendimento'] == 1 else 0, axis=1)\n",
        "\n",
        "test_df['positive'] = test_df.apply(lambda row: 1 if row['Atendimento'] == 2 else 0, axis=1)\n",
        "test_df['negative'] = test_df.apply(lambda row: 1 if row['Atendimento'] == 0 else 0, axis=1)\n",
        "test_df['neutral'] = test_df.apply(lambda row: 1 if row['Atendimento'] == 1 else 0, axis=1)\n",
        "\n",
        "train_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pid</th>\n",
              "      <th>req-text</th>\n",
              "      <th>Atendimento</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>529374</td>\n",
              "      <td>Cadastrei-me no CADSEI do Ministério das Comun...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>517464</td>\n",
              "      <td>Em detrimento à necessidade de informações ace...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>406897</td>\n",
              "      <td>Venho através desse solicitar um relatório ref...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>388221</td>\n",
              "      <td>Gostaria de ter acesso a toda informação sobre...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>451583</td>\n",
              "      <td>Prezado(a), bom dia! Sou Yuri Bandeira Brandão...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>505170</td>\n",
              "      <td>Boa tarde! Gostaria de obter informações sobre...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>354638</td>\n",
              "      <td>Quero solicitar informações sobre a quantidade...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>526968</td>\n",
              "      <td>Olá, bom dia, Sou contador (bacharel com regis...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>552107</td>\n",
              "      <td>Gostaria de saber o entendimento legal e qual ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>403296</td>\n",
              "      <td>Através do processo número 02016.000717/2015-0...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      pid                                           req-text  ...  negative  neutral\n",
              "0  529374  Cadastrei-me no CADSEI do Ministério das Comun...  ...         0        1\n",
              "1  517464  Em detrimento à necessidade de informações ace...  ...         0        1\n",
              "2  406897  Venho através desse solicitar um relatório ref...  ...         1        0\n",
              "3  388221  Gostaria de ter acesso a toda informação sobre...  ...         1        0\n",
              "4  451583  Prezado(a), bom dia! Sou Yuri Bandeira Brandão...  ...         0        1\n",
              "5  505170  Boa tarde! Gostaria de obter informações sobre...  ...         0        1\n",
              "6  354638  Quero solicitar informações sobre a quantidade...  ...         0        0\n",
              "7  526968  Olá, bom dia, Sou contador (bacharel com regis...  ...         0        0\n",
              "8  552107  Gostaria de saber o entendimento legal e qual ...  ...         0        1\n",
              "9  403296  Através do processo número 02016.000717/2015-0...  ...         0        0\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu5wUlQ5kTxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "42ae38cf-3ae3-47fd-dddc-5f2976203112"
      },
      "source": [
        "test_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pid</th>\n",
              "      <th>req-text</th>\n",
              "      <th>Atendimento</th>\n",
              "      <th>positive</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>514368</td>\n",
              "      <td>Estou fazendo um artigo acadêmico sobre fraude...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>452197</td>\n",
              "      <td>Prezados, gostarida da seguinte informação: So...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>533396</td>\n",
              "      <td>Gostaria de saber o número da minha CNH pelo m...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>567521</td>\n",
              "      <td>QUESTIONÁRIO Observações: 1) caso a Universida...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>295701</td>\n",
              "      <td>Prezados, Como se dará o financiamento das apo...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>478858</td>\n",
              "      <td>Boa Tarde. Gostaria de saber onde eu encontro ...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>562079</td>\n",
              "      <td>Prezados (as), Preciso de dados sobre as ferro...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>393850</td>\n",
              "      <td>Como profissional da área, gostaria de saber o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>533823</td>\n",
              "      <td>Solicito demonstrações/Relatórios ou dados ref...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>497668</td>\n",
              "      <td>Prezados, Por favor, gostaria de saber: - Qual...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      pid                                           req-text  ...  negative  neutral\n",
              "0  514368  Estou fazendo um artigo acadêmico sobre fraude...  ...         0        1\n",
              "1  452197  Prezados, gostarida da seguinte informação: So...  ...         0        1\n",
              "2  533396  Gostaria de saber o número da minha CNH pelo m...  ...         0        1\n",
              "3  567521  QUESTIONÁRIO Observações: 1) caso a Universida...  ...         0        0\n",
              "4  295701  Prezados, Como se dará o financiamento das apo...  ...         0        1\n",
              "5  478858  Boa Tarde. Gostaria de saber onde eu encontro ...  ...         0        0\n",
              "6  562079  Prezados (as), Preciso de dados sobre as ferro...  ...         0        1\n",
              "7  393850  Como profissional da área, gostaria de saber o...  ...         0        1\n",
              "8  533823  Solicito demonstrações/Relatórios ou dados ref...  ...         0        1\n",
              "9  497668  Prezados, Por favor, gostaria de saber: - Qual...  ...         0        0\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ6GJQP2amGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir('data/')\n",
        "train_df.to_csv('data/train_df.csv', index=False)\n",
        "test_df.to_csv('data/test_df.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWJVOsTHNO74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n",
        "        \n",
        "config = Config(\n",
        "    testing=False,\n",
        "    seed=1,\n",
        "    batch_size=params.get('BATCH_SIZE'),\n",
        "    lr=params.get('lr'),\n",
        "    epochs=params.get('epochs'),\n",
        "    hidden_sz=params.get('hidden_sz'),\n",
        "    max_seq_len=params.get('MAX_LEN'), # necessary to limit memory usage\n",
        "    max_vocab_size=params.get('max_vocab_size'),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWEsfzKbNPEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(config.seed)\n",
        "DATA_ROOT = Path(\"data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ux5_-oyTld1",
        "colab_type": "text"
      },
      "source": [
        "### Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97kO5UV5NPKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.data.dataset_readers import DatasetReader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEFPAZf7NPM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_cols = [\"negative\", \"neutral\", \"positive\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgTrDjOkPcED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.fields import TextField, MetadataField, ArrayField\n",
        "\n",
        "class SentimentDatasetReader(DatasetReader):\n",
        "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
        "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
        "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
        "        super().__init__(lazy=False)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    @overrides\n",
        "    def text_to_instance(self, tokens: List[Token], id: str=None, labels: np.ndarray=None) -> Instance:\n",
        "        sentence_field = TextField(tokens, self.token_indexers)\n",
        "        fields = {\"tokens\": sentence_field}\n",
        "        \n",
        "        id_field = MetadataField(id)\n",
        "        fields[\"id\"] = id_field\n",
        "        \n",
        "        if labels is None:\n",
        "            labels = np.zeros(len(label_cols))\n",
        "        label_field = ArrayField(array=labels)\n",
        "        fields[\"label\"] = label_field\n",
        "\n",
        "        return Instance(fields)\n",
        "    \n",
        "    @overrides\n",
        "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
        "        df = pd.read_csv(file_path)\n",
        "        if config.testing: df = df.head(1000)\n",
        "        for i, row in df.iterrows():\n",
        "            yield self.text_to_instance([Token(x) for x in self.tokenizer(row[data])], None, row[label_cols].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Po9wuzw-rZ9x"
      },
      "source": [
        "## ELMo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cU-g0PQ-rZ9_",
        "colab": {}
      },
      "source": [
        "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
        "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n",
        "\n",
        "# the token indexer is responsible for mapping tokens to integers\n",
        "token_indexer = ELMoTokenCharactersIndexer()\n",
        "\n",
        "def tokenizer(x: str):\n",
        "    return [w.text for w in SpacyWordSplitter(language=cur_language, pos_tags=False).split_words(x)[:config.max_seq_len]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s8p-gJ-9rZ-P",
        "colab": {}
      },
      "source": [
        "reader = SentimentDatasetReader(\n",
        "    tokenizer=tokenizer,\n",
        "    token_indexers={\"tokens\": token_indexer}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fX3yQmXurZ-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "20e3ca1e-3da9-4685-90f0-c66aa4721773"
      },
      "source": [
        "train_ds = reader.read(DATA_ROOT / \"train_df.csv\")\n",
        "print(len(train_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6982it [00:16, 432.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "6982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hrDWynosqme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9189b239-84ba-49b1-c07a-8edbd031a9fc"
      },
      "source": [
        "test_ds = reader.read(DATA_ROOT / \"test_df.csv\")\n",
        "print(len(test_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2993it [00:06, 470.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovgOH85rqC0J",
        "colab_type": "text"
      },
      "source": [
        "### Checking Tokens & Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0KqdOBUZrZ-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f668cf5-1c84-4e6c-981d-0713d6fecbf2"
      },
      "source": [
        "vars(train_ds[0].fields[\"tokens\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_indexed_tokens': None,\n",
              " '_indexer_name_to_indexed_token': None,\n",
              " '_token_indexers': {'tokens': <allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer at 0x7f973bcad898>},\n",
              " 'tokens': [Cadastrei,\n",
              "  -,\n",
              "  me,\n",
              "  no,\n",
              "  CADSEI,\n",
              "  do,\n",
              "  Ministério,\n",
              "  das,\n",
              "  Comunicações,\n",
              "  para,\n",
              "  acompanhamento,\n",
              "  de,\n",
              "  processo,\n",
              "  de,\n",
              "  Pensão,\n",
              "  Por,\n",
              "  Morte,\n",
              "  ,,\n",
              "  sendo,\n",
              "  que,\n",
              "  no,\n",
              "  momento,\n",
              "  do,\n",
              "  cadastro,\n",
              "  recebi,\n",
              "  a,\n",
              "  informação,\n",
              "  de,\n",
              "  que,\n",
              "  o,\n",
              "  mesmo,\n",
              "  havia,\n",
              "  sido,\n",
              "  feito,\n",
              "  com,\n",
              "  sucesso,\n",
              "  e,\n",
              "  que,\n",
              "  receberia,\n",
              "  a,\n",
              "  senha,\n",
              "  para,\n",
              "  acesso,\n",
              "  por,\n",
              "  e,\n",
              "  -,\n",
              "  mail,\n",
              "  .,\n",
              "  Ocorre,\n",
              "  que,\n",
              "  já,\n",
              "  transcorrido,\n",
              "  mais,\n",
              "  de,\n",
              "  24,\n",
              "  horas,\n",
              "  eu,\n",
              "  nada,\n",
              "  recebi,\n",
              "  e,\n",
              "  não,\n",
              "  consigo,\n",
              "  acompanhar,\n",
              "  processos,\n",
              "  de,\n",
              "  clientes,\n",
              "  .,\n",
              "  Será,\n",
              "  possível,\n",
              "  que,\n",
              "  em,\n",
              "  plena,\n",
              "  era,\n",
              "  da,\n",
              "  informática,\n",
              "  e,\n",
              "  da,\n",
              "  globalização,\n",
              "  possa,\n",
              "  um,\n",
              "  mero,\n",
              "  cadastro,\n",
              "  demorar,\n",
              "  tanto,\n",
              "  tempo,\n",
              "  para,\n",
              "  ser,\n",
              "  disponibilizada,\n",
              "  a,\n",
              "  senha,\n",
              "  ?,\n",
              "  O,\n",
              "  que,\n",
              "  tem,\n",
              "  de,\n",
              "  errado,\n",
              "  com,\n",
              "  o,\n",
              "  programa,\n",
              "  ?,\n",
              "  Agradeço,\n",
              "  a,\n",
              "  atenção,\n",
              "  e,\n",
              "  espero,\n",
              "  uma,\n",
              "  posição,\n",
              "  !]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N6lwAUZjrZ_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb7d9d07-3771-4991-a98d-d7fa8662bcbf"
      },
      "source": [
        "vars(train_ds[0].fields[\"label\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'array': array([0, 1, 0], dtype=object), 'padding_value': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t1TFE9kvrZ_O"
      },
      "source": [
        "### Prepare Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TsN2VpKSrZ_T",
        "colab": {}
      },
      "source": [
        "vocab = Vocabulary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZSDayQsgrZ_g"
      },
      "source": [
        "### Prepare Iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vc7kgux6rZ_p",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import BucketIterator\n",
        "\n",
        "iterator = BucketIterator(batch_size=config.batch_size, sorting_keys=[(\"tokens\", \"num_tokens\")],)\n",
        "iterator.index_with(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aXuusjbgraA1"
      },
      "source": [
        "### Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zl1OCBVEraA_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "74b59493-a196-4cbc-fa0d-c42f3bcf8137"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
        "from allennlp.nn.util import get_text_field_mask\n",
        "from allennlp.models import Model\n",
        "from allennlp.modules.text_field_embedders import TextFieldEmbedder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QoexCIfmraBM",
        "colab": {}
      },
      "source": [
        "class BaselineModel(Model):\n",
        "    def __init__(self, word_embeddings: TextFieldEmbedder,\n",
        "                 encoder: Seq2VecEncoder,\n",
        "                 out_sz: int=len(label_cols)):\n",
        "        super().__init__(vocab)\n",
        "        self.word_embeddings = word_embeddings\n",
        "        self.encoder = encoder\n",
        "        self.projection = nn.Linear(self.encoder.get_output_dim(), out_sz)\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "        \n",
        "    def forward(self, tokens: Dict[str, torch.Tensor],\n",
        "                id: Any, label: torch.Tensor) -> torch.Tensor:\n",
        "        mask = get_text_field_mask(tokens)\n",
        "        embeddings = self.word_embeddings(tokens)\n",
        "        state = self.encoder(embeddings, mask)\n",
        "        class_logits = self.projection(state)\n",
        "        \n",
        "        output = {\"class_logits\": class_logits}\n",
        "        output[\"loss\"] = self.loss(class_logits, label)\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t-RIhCDvraBb"
      },
      "source": [
        "### Prepare Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ng3lzsNMraBf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "56ce231e-1b8e-43b4-cbff-458bbb42f9be"
      },
      "source": [
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
        "\n",
        "# https://allennlp.org/elmo - PORTUGUESE BRWAC\n",
        "options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/contributed/pt/brwac/options.json'\n",
        "weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/contributed/pt/brwac/elmo_pt_weights_dgx1.hdf5'\n",
        "\n",
        "elmo_embedder = ElmoTokenEmbedder(options_file, weight_file)\n",
        "word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 547/547 [00:00<00:00, 411383.23B/s]\n",
            "100%|██████████| 374434792/374434792 [00:23<00:00, 16187254.56B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZAbX3qNtraBx",
        "colab": {}
      },
      "source": [
        "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
        "\n",
        "# Create Encoder\n",
        "encoder: Seq2VecEncoder = PytorchSeq2VecWrapper(nn.LSTM(word_embeddings.get_output_dim(), config.hidden_sz, bidirectional=True, batch_first=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QsgdLD-zraCB",
        "colab": {}
      },
      "source": [
        "model = BaselineModel(word_embeddings, encoder)\n",
        "\n",
        "if USE_GPU: model.cuda()\n",
        "else: model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c9h0Vmo0raCO"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0lBrE6U_raCP",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t31y1Lh-raCZ",
        "colab": {}
      },
      "source": [
        "from allennlp.training.trainer import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    iterator=iterator,\n",
        "    train_dataset=train_ds,\n",
        "    cuda_device=0 if USE_GPU else -1,\n",
        "    num_epochs=config.epochs,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fB45IOSfraCg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2dea129e-2513-40e4-e1ef-c8f3ab4c5278"
      },
      "source": [
        "metrics = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.6429 ||: 100%|██████████| 110/110 [01:03<00:00,  1.72it/s]\n",
            "loss: 0.6321 ||: 100%|██████████| 110/110 [01:03<00:00,  1.72it/s]\n",
            "loss: 0.6266 ||: 100%|██████████| 110/110 [01:07<00:00,  1.64it/s]\n",
            "loss: 0.6214 ||: 100%|██████████| 110/110 [01:07<00:00,  1.63it/s]\n",
            "loss: 0.6148 ||: 100%|██████████| 110/110 [01:07<00:00,  1.64it/s]\n",
            "loss: 0.6080 ||: 100%|██████████| 110/110 [01:07<00:00,  1.64it/s]\n",
            "loss: 0.5998 ||: 100%|██████████| 110/110 [01:07<00:00,  1.63it/s]\n",
            "loss: 0.5931 ||: 100%|██████████| 110/110 [01:07<00:00,  1.63it/s]\n",
            "loss: 0.5857 ||: 100%|██████████| 110/110 [01:07<00:00,  1.63it/s]\n",
            "loss: 0.5795 ||: 100%|██████████| 110/110 [01:07<00:00,  1.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MQF-AbNGsr_j"
      },
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_nLYjz8BssAM",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import DataIterator\n",
        "from tqdm import tqdm\n",
        "from scipy.special import expit # the sigmoid function\n",
        "\n",
        "def tonp(tsr): return tsr.detach().cpu().numpy()\n",
        "\n",
        "class Predictor:\n",
        "    def __init__(self, model: Model, iterator: DataIterator,\n",
        "                 cuda_device: int=-1) -> None:\n",
        "        self.model = model\n",
        "        self.iterator = iterator\n",
        "        self.cuda_device = cuda_device\n",
        "        \n",
        "    def _extract_data(self, batch) -> np.ndarray:\n",
        "        out_dict = self.model(**batch)\n",
        "        return expit(tonp(out_dict[\"class_logits\"]))\n",
        "    \n",
        "    def predict(self, ds: Iterable[Instance]) -> np.ndarray:\n",
        "        pred_generator = self.iterator(ds, num_epochs=1, shuffle=False)\n",
        "        self.model.eval()\n",
        "        pred_generator_tqdm = tqdm(pred_generator,\n",
        "                                   total=self.iterator.get_num_batches(ds))\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for batch in pred_generator_tqdm:\n",
        "                batch = nn_util.move_to_device(batch, self.cuda_device)\n",
        "                preds.append(self._extract_data(batch))\n",
        "        return np.concatenate(preds, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBkIHIjYsTww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import BasicIterator\n",
        "\n",
        "# iterate over the dataset without changing its order\n",
        "seq_iterator = BasicIterator(batch_size=64)\n",
        "seq_iterator.index_with(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHMW_6P3sY0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecdb470c-c387-4e7b-ed3d-fe04d77a3a11"
      },
      "source": [
        "predictor = Predictor(model, seq_iterator, cuda_device=0 if USE_GPU else -1)\n",
        "test_preds = predictor.predict(test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 47/47 [00:38<00:00,  1.23it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYR_1IWrtWLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c40a3319-9542-44ad-94f0-286d19b5f9c0"
      },
      "source": [
        "# Convert to predictions\n",
        "y_pred_bool = np.argmax(test_preds, axis=1)\n",
        "y_pred_bool[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0, 2, 0, 2, 2, 2, 0, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpYPOEZ2sccy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "3f18dc0a-88b2-42a1-a23f-94d26d8091e6"
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "test_y = test_df[label]\n",
        "\n",
        "f1 = f1_score(test_y, y_pred_bool, average='weighted')\n",
        "print(f\"Best Test F1-Score: {f1:.3f}\")    \n",
        "print(classification_report(test_y, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Test F1-Score: 0.405\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.42      0.42       958\n",
            "           1       0.40      0.22      0.28      1006\n",
            "           2       0.44      0.63      0.51      1029\n",
            "\n",
            "    accuracy                           0.42      2993\n",
            "   macro avg       0.42      0.42      0.40      2993\n",
            "weighted avg       0.42      0.42      0.41      2993\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fYrfeNKi_Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_dir = '/content/gdrive/My Drive/Colab Notebooks/outputs/elmo/'  + params.get('exp') + '/' + now \n",
        "\n",
        "try:\n",
        "  os.mkdir(output_dir)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "from json import dumps\n",
        "\n",
        "with open(output_dir + '/params.json', 'w') as f:\n",
        "  f.write(dumps(params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlrsqYPVjA7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(output_dir + \"/model.th\", 'wb') as f:\n",
        "    torch.save(model.state_dict(), f)\n",
        "\n",
        "vocab.save_to_files(output_dir + \"/vocabulary\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SuWUmnHjC5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(output_dir + '/classification_report.txt', 'w') as f:\n",
        "  f.write(classification_report(test_y, y_pred_bool))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}